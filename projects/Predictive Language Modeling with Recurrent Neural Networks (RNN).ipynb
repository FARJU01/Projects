{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174a6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb904be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b7e038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f52f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=sequence.pad_sequences(train_data,MAXLEN)\n",
    "test_data=sequence.pad_sequences(test_data,MAXLEN)\n",
    "len(train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1c9dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2843041 (10.85 MB)\n",
      "Trainable params: 2843041 (10.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6941354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 157s 237ms/step - loss: 0.4455 - accuracy: 0.7885 - val_loss: 0.2929 - val_accuracy: 0.8818\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 191s 306ms/step - loss: 0.2571 - accuracy: 0.9017 - val_loss: 0.2877 - val_accuracy: 0.8904\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 186s 298ms/step - loss: 0.2010 - accuracy: 0.9275 - val_loss: 0.3046 - val_accuracy: 0.8718\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 191s 305ms/step - loss: 0.1588 - accuracy: 0.9441 - val_loss: 0.3473 - val_accuracy: 0.8842\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 184s 295ms/step - loss: 0.1347 - accuracy: 0.9552 - val_loss: 0.3393 - val_accuracy: 0.8880\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 167s 267ms/step - loss: 0.1118 - accuracy: 0.9632 - val_loss: 0.3241 - val_accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 163s 261ms/step - loss: 0.0945 - accuracy: 0.9704 - val_loss: 0.3441 - val_accuracy: 0.8838\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 176s 282ms/step - loss: 0.0803 - accuracy: 0.9751 - val_loss: 0.3570 - val_accuracy: 0.8730\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 167s 267ms/step - loss: 0.0682 - accuracy: 0.9785 - val_loss: 0.3750 - val_accuracy: 0.8810\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 161s 258ms/step - loss: 0.0591 - accuracy: 0.9825 - val_loss: 0.3863 - val_accuracy: 0.8768\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "history=model.fit(train_data,train_labels,epochs=10,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce09de07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\windows\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 58s 72ms/step - loss: 0.4520 - accuracy: 0.8595\n",
      "[0.45200157165527344, 0.8594800233840942]\n"
     ]
    }
   ],
   "source": [
    "model.save(\"lstm.h5\")\n",
    "new_model = tf.keras.models.load_model('lstm.h5')\n",
    "results=new_model.evaluate(test_data,test_labels)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b088a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 60s 77ms/step - loss: 0.4520 - accuracy: 0.8595\n",
      "[0.45200157165527344, 0.8594800233840942]\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(test_data,test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70f736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297b3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fawn : 34701\n",
      "tsukino : 52006\n",
      "nunnery : 52007\n",
      "sonja : 16816\n",
      "vani : 63951\n",
      "woods : 1408\n",
      "spiders : 16115\n",
      "hanging : 2345\n",
      "woody : 2289\n",
      "trawling : 52008\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  12  17  13 477  10  25   5 103   9 171]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(list(word_index.keys())[i],':',list(word_index.values())[i])\n",
    "fawn : 34701\n",
    "tsukino : 52006\n",
    "nunnery : 52007\n",
    "sonja : 16816\n",
    "vani : 63951\n",
    "woods : 1408\n",
    "spiders : 16115\n",
    "hanging : 2345\n",
    "woody : 2289\n",
    "trawling : 52008\n",
    "def encode_text(text):\n",
    "    tokens=keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens=[word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens],MAXLEN)[0]\n",
    "text=\"that movie was amazing, i have to watch it again\"\n",
    "encoded=encode_text(text)\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5738877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was amazing i have to watch it again\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index={value:key for (key,value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD=0\n",
    "    text=\"\"\n",
    "    for num in integers:\n",
    "        if num!=PAD:\n",
    "            text+=reverse_word_index[num] +\" \"\n",
    "            \n",
    "    return text[:-1]\n",
    "\n",
    "print(decode_integers(encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efbb5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "[0.96824074]\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "[0.3615175]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text=encode_text(text)\n",
    "    pred=encoded_text.reshape(1,250) #converting vector to 2d\n",
    "    result=model.predict(pred)\n",
    "    print(result[0])\n",
    "positive_review=\"That was a good movie, i will definitely watch it again\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review=\"Don't waste your time watching this movie, so disappointing\"\n",
    "predict(negative_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310580f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 2s 2us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "055666a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text :  1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
    "print(\"Length of text : \",len(text))\n",
    "Length_of_text :  1115394\n",
    "print(text[:250])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16162358",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98b70de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "char2idx={u:i for i,u in enumerate(vocab)}\n",
    "idx2char=np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[t] for t in text])\n",
    "\n",
    "text_as_int=text_to_int(text)\n",
    "print('Text:',text[0:13])\n",
    "print('Encoded:',text_to_int(text[:13]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dccd8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints=ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_to_int(text[:13])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e46bb695",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100 \n",
    "examples_per_epoch = len(text)//(seq_length+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f423d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "def split_input_target(chunk):  \n",
    "    input_text = chunk[:-1]  \n",
    "    target_text = chunk[1:]  \n",
    "    return input_text, target_text  \n",
    "\n",
    "dataset = sequences.map(split_input_target) \n",
    "for x, y in dataset.take(2):\n",
    "    print(\"\\n\\nEXAMPLE\\n\")\n",
    "    print(\"INPUT\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOUTPUT\")\n",
    "    print(int_to_text(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ac9fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5330241 (20.33 MB)\n",
      "Trainable params: 5330241 (20.33 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                batch_input_shape=[batch_size, None]),\n",
    "      tf.keras.layers.LSTM(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "      tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model=build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfbc5c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n",
      "(64, 100, 65)\n",
      "64\n",
      "tf.Tensor(\n",
      "[[[ 1.3251001e-03  3.4430767e-03  2.0326218e-03 ... -5.0887601e-03\n",
      "   -5.8780783e-03  2.6177586e-04]\n",
      "  [ 2.1975916e-03  6.5987865e-03  9.6542435e-04 ... -3.8792577e-03\n",
      "   -1.6570603e-03  7.6554157e-04]\n",
      "  [ 6.0186153e-03 -4.9537304e-04  8.0355564e-03 ... -6.1021307e-03\n",
      "   -2.4897940e-03 -4.0712054e-03]\n",
      "  ...\n",
      "  [ 2.2069428e-02  9.4147148e-03  3.7962091e-03 ...  1.7359682e-03\n",
      "   -2.0415823e-03 -5.5994829e-03]\n",
      "  [ 1.2643751e-02  5.2989228e-03  8.3993217e-03 ...  7.6447381e-04\n",
      "    4.3322295e-03 -4.2372751e-03]\n",
      "  [ 9.3948161e-03  2.2232563e-03  1.9938436e-03 ...  2.6804060e-03\n",
      "   -1.5712748e-03 -4.9629519e-03]]\n",
      "\n",
      " [[-2.4788573e-03 -1.9733938e-03 -4.8176409e-03 ...  1.9501196e-03\n",
      "   -4.3313950e-03 -5.3163874e-04]\n",
      "  [ 1.1893604e-03 -2.1203582e-03 -3.2369792e-04 ... -2.5113593e-03\n",
      "   -6.2564849e-03  2.3356115e-03]\n",
      "  [ 1.1956047e-03  4.9231229e-03 -1.6232933e-03 ... -5.6215636e-03\n",
      "   -7.7098832e-03  4.9132360e-03]\n",
      "  ...\n",
      "  [ 2.9427786e-03  3.2198029e-03  1.2967040e-02 ...  6.3436595e-04\n",
      "   -4.8407381e-03 -6.8938290e-04]\n",
      "  [ 2.4627796e-03  3.2899810e-03  9.4892997e-03 ...  1.1298392e-03\n",
      "   -3.6468604e-03 -3.1199604e-03]\n",
      "  [ 2.1473661e-03  3.2140068e-03  5.7108910e-03 ...  2.8713599e-03\n",
      "   -2.6688520e-03 -4.3036230e-03]]\n",
      "\n",
      " [[-5.6828186e-03  9.2658494e-04 -6.8921717e-03 ...  1.8744749e-03\n",
      "    7.9649501e-03 -3.9495789e-03]\n",
      "  [-7.9298322e-04  5.4070877e-04 -9.2737377e-04 ... -1.5809863e-03\n",
      "    1.0099224e-03 -1.7527023e-03]\n",
      "  [-3.9005815e-04 -9.5278956e-05  1.1540359e-03 ... -2.8178873e-03\n",
      "   -2.9570896e-03 -3.5842154e-03]\n",
      "  ...\n",
      "  [ 1.1315239e-02  5.4732868e-03 -1.0709353e-02 ...  2.1299892e-03\n",
      "    6.3762367e-03 -2.6981502e-03]\n",
      "  [ 7.9475194e-03  8.1082564e-03 -8.3400654e-03 ...  2.8546781e-03\n",
      "    1.0761535e-02 -4.4264551e-03]\n",
      "  [ 6.2868930e-03  6.3264049e-03 -8.6282529e-03 ...  7.2229048e-03\n",
      "    2.6073959e-03 -4.0004211e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.0555599e-04  6.9210809e-03 -1.0125050e-03 ... -3.6222530e-03\n",
      "   -3.1724155e-03  2.6169932e-03]\n",
      "  [-3.7262205e-03  7.1685784e-04 -2.1017825e-03 ...  4.3251775e-03\n",
      "   -3.2530515e-03  5.0967932e-03]\n",
      "  [-1.2059181e-03  3.2120210e-04 -1.6607761e-03 ...  3.2808718e-03\n",
      "   -8.9165401e-03  5.0466945e-03]\n",
      "  ...\n",
      "  [ 2.4353911e-03  1.0319553e-02  3.4715915e-03 ...  2.1866111e-03\n",
      "    3.6799908e-03 -6.7870766e-03]\n",
      "  [ 1.6104641e-03  8.3218664e-03 -2.8817158e-04 ...  6.0463762e-03\n",
      "    1.7787414e-03 -1.6288341e-03]\n",
      "  [ 4.8069740e-03  9.4116796e-03 -2.5995956e-03 ...  5.1967809e-03\n",
      "    2.9511480e-03 -1.4727552e-03]]\n",
      "\n",
      " [[ 6.4978786e-03 -1.8770682e-03  2.5097928e-03 ...  5.2295416e-03\n",
      "   -7.0477966e-03 -4.5168633e-03]\n",
      "  [ 7.0058233e-03  4.4736215e-03  1.2838192e-03 ...  4.7450485e-03\n",
      "   -2.4623200e-03 -4.2342665e-03]\n",
      "  [ 5.6067538e-03  7.3177787e-03  7.4514197e-03 ...  7.0880740e-03\n",
      "   -5.1049697e-03 -4.4447416e-03]\n",
      "  ...\n",
      "  [ 6.4162835e-03  4.3501230e-03 -5.6589637e-03 ...  3.3910028e-03\n",
      "    1.4592574e-03 -1.9245658e-03]\n",
      "  [ 8.4451130e-03  2.1444657e-03 -1.1534202e-03 ...  1.2971102e-03\n",
      "   -3.2393436e-03 -3.5594526e-04]\n",
      "  [ 6.8325289e-03  3.2076251e-04  7.2948867e-05 ...  5.0065789e-04\n",
      "   -5.7351557e-03 -2.8950246e-03]]\n",
      "\n",
      " [[ 1.3251001e-03  3.4430767e-03  2.0326218e-03 ... -5.0887601e-03\n",
      "   -5.8780783e-03  2.6177586e-04]\n",
      "  [ 2.1975916e-03  6.5987865e-03  9.6542435e-04 ... -3.8792577e-03\n",
      "   -1.6570603e-03  7.6554157e-04]\n",
      "  [ 1.3437073e-03  1.5240862e-03  5.4121921e-03 ... -6.0318704e-03\n",
      "    4.7537452e-04  7.8286283e-04]\n",
      "  ...\n",
      "  [ 2.9622161e-04  4.3071993e-03  4.5944685e-03 ...  9.7994283e-03\n",
      "   -3.1187484e-04 -1.5644520e-03]\n",
      "  [ 6.7749852e-04  2.2564814e-03  5.4669390e-03 ...  6.8160594e-03\n",
      "   -2.9380757e-03 -5.2629337e-03]\n",
      "  [-1.4408133e-03 -3.5839481e-04 -7.7527319e-04 ...  7.8147920e-03\n",
      "   -7.4111116e-03 -5.7974425e-03]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)  \n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  \n",
    "print(example_batch_predictions.shape)\n",
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ff7c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 0.0013251   0.00344308  0.00203262 ... -0.00508876 -0.00587808\n",
      "   0.00026178]\n",
      " [ 0.00219759  0.00659879  0.00096542 ... -0.00387926 -0.00165706\n",
      "   0.00076554]\n",
      " [ 0.00601862 -0.00049537  0.00803556 ... -0.00610213 -0.00248979\n",
      "  -0.00407121]\n",
      " ...\n",
      " [ 0.02206943  0.00941471  0.00379621 ...  0.00173597 -0.00204158\n",
      "  -0.00559948]\n",
      " [ 0.01264375  0.00529892  0.00839932 ...  0.00076447  0.00433223\n",
      "  -0.00423728]\n",
      " [ 0.00939482  0.00222326  0.00199384 ...  0.00268041 -0.00157127\n",
      "  -0.00496295]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "827c77c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[ 1.32510008e-03  3.44307674e-03  2.03262176e-03  1.85602531e-03\n",
      "  2.21742853e-03  2.53064930e-03 -1.65632018e-03  3.88318626e-03\n",
      " -5.86581766e-04  2.57285684e-03  2.26133107e-03 -2.53481371e-03\n",
      "  6.08188566e-03  2.48184148e-03  1.77756604e-03 -6.78903144e-03\n",
      "  7.00137112e-04 -3.31419054e-03 -2.14862870e-03 -3.74247378e-04\n",
      " -9.56521253e-04  1.17776846e-03 -8.17543268e-03 -5.03043924e-03\n",
      " -5.11549762e-04  1.95413129e-03  5.36165759e-03 -1.21163984e-03\n",
      " -1.52174174e-03  2.20200920e-04 -5.00089489e-03  1.55254756e-03\n",
      " -1.82190724e-03  1.23672618e-03 -1.59741449e-03 -3.95397050e-03\n",
      "  1.46192324e-03 -2.33040797e-03 -4.10161028e-03 -2.93789781e-04\n",
      " -4.31525335e-03 -6.02600456e-04  6.84375875e-04  3.74924159e-04\n",
      "  8.22579302e-03  3.40878684e-03 -1.05858105e-03 -3.29450145e-03\n",
      " -5.20249596e-04  1.26444465e-02  2.22149701e-03  5.40079037e-03\n",
      " -1.11500034e-04  2.68878159e-03 -4.21652244e-03  1.44922850e-03\n",
      "  2.36101379e-03 -3.58467922e-03  3.14204022e-03  3.82014504e-03\n",
      "  5.92279830e-05 -4.07026708e-03 -5.08876005e-03 -5.87807829e-03\n",
      "  2.61775858e-04], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6faac75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(pred, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eebb5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MmtHDj! lW3PfB&Y heRmoSt dWStS3'ZPRgXC.N t?sbBs'cGDmVtouZqp bIEq$poJfOtk!B$AatsKeJ:re$?z'ZqYroM,aJe$\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0dec5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae6dbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b8eaa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "172/172 [==============================] - 4990s 29s/step - loss: 2.5741\n",
      "Epoch 2/2\n",
      "172/172 [==============================] - 4970s 29s/step - loss: 1.8780\n"
     ]
    }
   ],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "history = model.fit(data, epochs=2, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49e9f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e0c8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romeo said.\n",
      "\n",
      "PLBRYET\n",
      "Hus by the nable and rended gouser farse.\n",
      "\n",
      "MUKINGBE:\n",
      "God I am stort of her.\n",
      "\n",
      "Fwast of RPiRES:\n",
      "Io mast you would ecress'd shose it Carinam!\n",
      "\n",
      "All:\n",
      "In cexs; fouch alle fires fither.\n",
      "\n",
      "LAVY:\n",
      "Bustak' dight nome. he colllen, gearow liniom\n",
      "Mistarralist when that dive foung offreach his,\n",
      "BefI Then Jusines is Gothing trared for the hone.\n",
      "\n",
      "Plotter:\n",
      "These news your iences, In.\n",
      "\n",
      "TRANIO:\n",
      "Clove, seg,\n",
      "Live me hus gors; I so not with of a leady\n",
      "Nore not soen sovelf\n",
      "Is balla will me to far to that wean.\n",
      "\n",
      "Ammant:\n",
      "Cood with sw'lv all well me and neart?\n",
      "\n",
      "First Kerether:\n",
      "Hith so you ach well, our donghol surs, mugts infucest your that I will\n",
      "Sto befose than amper we dearn,\n",
      "Toums, for the marise, noverd we and likes,\n",
      "Camy!\n",
      "\n",
      "Binot Sitizen:\n",
      "The keot all besty musting bihe, id yourd rove and than A alur-\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 800\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 1.0\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return (start_string + ''.join(text_generated))\n",
    "inp=\"Romeo said\"\n",
    "print(generate_text(model,inp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696660d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
